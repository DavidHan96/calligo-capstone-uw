import pandas as pd
import numpy as np
from xgboost import XGBClassifier
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from functools import reduce

# Load Data to Weekly
kpi_files = {
    'CPIAUCSL.csv': 'cpi',
    'GDP.csv': 'gdp',
    'HOUST.csv': 'housing_starts',
    'M2REAL.csv': 'm2_money_supply',
    'MORTGAGE30US.csv': 'mortgage_rate',
    'PERMIT.csv': 'building_permits',
    'PPIACO.csv': 'ppi',
    'T10Y2Y.csv': 'yield_curve',
    'TLRESCONS.csv': 'construction_spending',
    'UNRATE.csv': 'unemployment_rate',
    'WPU0851.csv': 'lumber_price'
}

dfs = []
for file, col_name in kpi_files.items():
    df = pd.read_csv(file)
    df.columns = ['date', col_name]
    df['date'] = pd.to_datetime(df['date'])
    df = df.set_index('date').resample('W').ffill().reset_index()
    dfs.append(df)

merged_df = reduce(lambda left, right: pd.merge(left, right, on='date', how='inner'), dfs)
merged_df = merged_df.sort_values('date').reset_index(drop=True)

# Target Variable
merged_df['target'] = np.where(merged_df['lumber_price'].shift(-1) > merged_df['lumber_price'], 1, 0)
merged_df = merged_df.dropna().reset_index(drop=True)

# Feature Engineering
merged_df['month'] = merged_df['date'].dt.month
merged_df['is_summer'] = merged_df['month'].isin([6,7,8]).astype(int)
merged_df['month_sin'] = np.sin(2 * np.pi * merged_df['month']/12)
merged_df['month_cos'] = np.cos(2 * np.pi * merged_df['month']/12)
merged_df['lumber_pct_change_1w'] = merged_df['lumber_price'].pct_change(1)
merged_df['lumber_pct_change_4w'] = merged_df['lumber_price'].pct_change(4)
merged_df['lumber_sma_4w'] = merged_df['lumber_price'].rolling(4).mean()
merged_df['lumber_sma_12w'] = merged_df['lumber_price'].rolling(12).mean()
merged_df['lumber_volatility_4w'] = merged_df['lumber_price'].rolling(4).std()
merged_df = merged_df.dropna().reset_index(drop=True)

# Train/Test Split
X = merged_df.drop(columns=['date', 'target', 'lumber_price'])
y = merged_df['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)

# XGBoost Model with scale_pos_weight
model = XGBClassifier(n_estimators=50, max_depth=3, learning_rate=0.1, scale_pos_weight=2, random_state=42)
model.fit(X_train, y_train)

# Predictions and Evaluation
y_pred = model.predict(X_test)

print("Classification Report ")
print(classification_report(y_test, y_pred, labels=[0,1]))

print("Model Parameters")
print(model.get_params())

print("Sample Predictions")
print("Predicted:", y_pred[:10])
print("Actual:   ", y_test.values[:10])

print("Dataset Shape")
print("Training set shape:", X_train.shape)
print("Test set shape:", X_test.shape)
